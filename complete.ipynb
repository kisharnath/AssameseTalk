{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8M97y9vJiw4E3mi2KnH6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kisharnath/AssameseTalk/blob/main/complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
      ],
      "metadata": {
        "id": "s-CuH9epZ9Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/IndicTrans2/huggingface_interface"
      ],
      "metadata": {
        "id": "NhQPRK4waCDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
        "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
        "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
        "!python3 -m pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
        "%cd IndicTransTokenizer\n",
        "!python3 -m pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "id": "ZHQy3lwvaFOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
        "%cd IndicTransTokenizer\n",
        "!python3 -m pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UvzJJcSx7lw",
        "outputId": "7643e786-16c9-42ef-fa7e-a09cf8117dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IndicTransTokenizer' already exists and is not an empty directory.\n",
            "/content/IndicTrans2/huggingface_interface/IndicTransTokenizer\n",
            "Obtaining file:///content/IndicTrans2/huggingface_interface/IndicTransTokenizer\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransTokenizer==0.1.1)\n",
            "  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-mx0fi_9i/indic-nlp-library-it2_9c2f7ae6c370416b8034adc29ced8529\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-mx0fi_9i/indic-nlp-library-it2_9c2f7ae6c370416b8034adc29ced8529\n",
            "  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 18e85551b0b331a65d11acf869afd4cfa615bc4c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools==68.2.2 in /usr/local/lib/python3.10/dist-packages (from IndicTransTokenizer==0.1.1) (68.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from IndicTransTokenizer==0.1.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from IndicTransTokenizer==0.1.1) (0.1.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from IndicTransTokenizer==0.1.1) (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from IndicTransTokenizer==0.1.1) (4.38.2)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (0.4.0)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.0.0)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.25.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransTokenizer==0.1.1) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransTokenizer==0.1.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransTokenizer==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransTokenizer==0.1.1) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransTokenizer==0.1.1) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransTokenizer==0.1.1) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->IndicTransTokenizer==0.1.1) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransTokenizer==0.1.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransTokenizer==0.1.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransTokenizer==0.1.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransTokenizer==0.1.1) (2024.2.2)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.21 in /usr/local/lib/python3.10/dist-packages (from sphinx_rtd_theme->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (0.18.1)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx_rtd_theme->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->IndicTransTokenizer==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.0.7)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.1) (1.4.1)\n",
            "Installing collected packages: IndicTransTokenizer\n",
            "  Attempting uninstall: IndicTransTokenizer\n",
            "    Found existing installation: IndicTransTokenizer 0.1.1\n",
            "    Uninstalling IndicTransTokenizer-0.1.1:\n",
            "      Successfully uninstalled IndicTransTokenizer-0.1.1\n",
            "  Running setup.py develop for IndicTransTokenizer\n",
            "Successfully installed IndicTransTokenizer-0.1.1\n",
            "/content/IndicTrans2/huggingface_interface\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
        "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "quantization = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "bSLlZwBKyDxA",
        "outputId": "b549d59b-300b-4c14-ae3b-46a8a6fe3265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'IndicProcessor' from 'IndicTransTokenizer' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5d0ce939eca2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mIndicTransTokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndicProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndicTransTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'IndicProcessor' from 'IndicTransTokenizer' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
        "    if quantization == \"4-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    elif quantization == \"8-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    else:\n",
        "        qconfig = None\n",
        "\n",
        "    tokenizer = IndicTransTokenizer(direction=direction)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        ckpt_dir,\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        quantization_config=qconfig,\n",
        "    )\n",
        "\n",
        "    if qconfig == None:\n",
        "        model = model.to(DEVICE)\n",
        "        if DEVICE == \"cuda\":\n",
        "            model.half()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
        "    translations = []\n",
        "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
        "        batch = input_sentences[i : i + BATCH_SIZE]\n",
        "\n",
        "        # Preprocess the batch and extract entity mappings\n",
        "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "        # Tokenize the batch and generate input encodings\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            src=True,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Generate translations using the model\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                use_cache=True,\n",
        "                min_length=0,\n",
        "                max_length=256,\n",
        "                num_beams=5,\n",
        "                num_return_sequences=1,\n",
        "            )\n",
        "\n",
        "        # Decode the generated tokens into text\n",
        "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
        "\n",
        "        # Postprocess the translations, including entity replacement\n",
        "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "        del inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return translations"
      ],
      "metadata": {
        "id": "PU9AmQuMaw0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**English to indic**"
      ],
      "metadata": {
        "id": "Hqnji3YOcD3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assamese():\n",
        "  en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "  en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
        "\n",
        "  ip = IndicProcessor(inference=True)\n",
        "\n",
        "  en_sents = [\n",
        "      \"When I was young, I used to go to the park every day.\",\n",
        "      \"He has many old books, which he inherited from his ancestors.\",\n",
        "      \"I can't figure out how to solve my problem.\",\n",
        "      \"She is very hardworking and intelligent, which is why she got all the good marks.\",\n",
        "      \"We watched a new movie last week, which was very inspiring.\",\n",
        "      \"If you had met me at that time, we would have gone out to eat.\",\n",
        "      \"She went to the market with her sister to buy a new sari.\",\n",
        "      \"Raj told me that he is going to his grandmother's house next month.\",\n",
        "      \"All the kids were having fun at the party and were eating lots of sweets.\",\n",
        "      \"My friend has invited me to his birthday party, and I will give him a gift.\",\n",
        "  ]\n",
        "\n",
        "  src_lang, tgt_lang = \"eng_Latn\", \"asm_Beng\"\n",
        "  hi_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
        "\n",
        "  print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "  for input_sentence, translation in zip(en_sents, hi_translations):\n",
        "      print(f\"{src_lang}: {input_sentence}\")\n",
        "      print(f\"{tgt_lang}: {translation}\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "#del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "id": "yy-T9z7ja2Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Indic to English**"
      ],
      "metadata": {
        "id": "bEGvrsxTb603"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_english():\n",
        "  indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-1B\"  # ai4bharat/indictrans2-indic-en-dist-200M\n",
        "  indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, \"indic-en\", \"\")\n",
        "\n",
        "  ip = IndicProcessor(inference=True)\n",
        "\n",
        "  hi_sents = [\n",
        "      \"जब मैं छोटा था, मैं हर रोज़ पार्क जाता था।\",\n",
        "      \"उसके पास बहुत सारी पुरानी किताबें हैं, जिन्हें उसने अपने दादा-परदादा से विरासत में पाया।\",\n",
        "      \"मुझे समझ में नहीं आ रहा कि मैं अपनी समस्या का समाधान कैसे ढूंढूं।\",\n",
        "      \"वह बहुत मेहनती और समझदार है, इसलिए उसे सभी अच्छे मार्क्स मिले।\",\n",
        "      \"हमने पिछले सप्ताह एक नई फिल्म देखी जो कि बहुत प्रेरणादायक थी।\",\n",
        "      \"अगर तुम मुझे उस समय पास मिलते, तो हम बाहर खाना खाने चलते।\",\n",
        "      \"वह अपनी दीदी के साथ बाजार गयी थी ताकि वह नई साड़ी खरीद सके।\",\n",
        "      \"राज ने मुझसे कहा कि वह अगले महीने अपनी नानी के घर जा रहा है।\",\n",
        "      \"सभी बच्चे पार्टी में मज़ा कर रहे थे और खूब सारी मिठाइयाँ खा रहे थे।\",\n",
        "      \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\",\n",
        "  ]\n",
        "  src_lang, tgt_lang = \"hin_Deva\", \"eng_Latn\"\n",
        "  en_translations = batch_translate(hi_sents, src_lang, tgt_lang, indic_en_model, indic_en_tokenizer, ip)\n",
        "\n",
        "\n",
        "  print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "  for input_sentence, translation in zip(hi_sents, en_translations):\n",
        "      print(f\"{src_lang}: {input_sentence}\")\n",
        "      print(f\"{tgt_lang}: {translation}\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "#del indic_en_tokenizer, indic_en_model"
      ],
      "metadata": {
        "id": "-nr2Tj61b-cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_english()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "l6EuqDPxw9E1",
        "outputId": "33e12bd0-a5a6-48da-a2e7-dcfcf33b7440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'IndicTransTokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-16a56ac5e569>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-3704923061db>\u001b[0m in \u001b[0;36mget_english\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mindic_en_ckpt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ai4bharat/indictrans2-indic-en-1B\"\u001b[0m  \u001b[0;31m# ai4bharat/indictrans2-indic-en-dist-200M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mindic_en_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_en_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model_and_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindic_en_ckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"indic-en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndicProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-42749fc931ab>\u001b[0m in \u001b[0;36minitialize_model_and_tokenizer\u001b[0;34m(ckpt_dir, direction, quantization)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mqconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndicTransTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     model = AutoModelForSeq2SeqLM.from_pretrained(\n\u001b[1;32m     19\u001b[0m         \u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'IndicTransTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now server set up**"
      ],
      "metadata": {
        "id": "mDYB7G4kcSbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"uvicorn[standard]\" nest-asyncio pyngrok fastapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIOBojrUcVmP",
        "outputId": "c9d52e3c-f234-47bb-c193-0354f2c49ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uvicorn[standard]\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.4-py3-none-any.whl (22 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]) (4.10.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard])\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.6.3)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.2.0)\n",
            "Installing collected packages: websockets, uvloop, python-dotenv, pyngrok, httptools, h11, watchfiles, uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.110.0 h11-0.14.0 httptools-0.6.1 pyngrok-7.1.4 python-dotenv-1.0.1 starlette-0.36.3 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transliteration By Ai4Bharat**"
      ],
      "metadata": {
        "id": "0xYK2oIXeNTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ai4bharat-transliteration"
      ],
      "metadata": {
        "id": "E7T4b2XoeTck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ai4bharat.transliteration import XlitEngine\n",
        "e = XlitEngine(\"as\", beam_width=20, rescore=True)\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}\n",
        "@app.get('/{word}')\n",
        "async def transalet(word: str):\n",
        "  out = e.translit_sentence(word)\n",
        "  print(out)\n",
        "  return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAzMZG5Ce4Qe",
        "outputId": "6c19f7e2-15f5-4b29-e600-441df28f9d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB100% (121.0 of 121.0) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.10/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/model.zip\n",
            "Models downloaded to: /usr/local/lib/python3.10/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0\n",
            "NOTE: When uninstalling this library, REMEMBER to delete the models manually\n",
            "Downloading language model probablitites dictionaries for rescoring module\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB100% (812.0 of 812.0) |################| Elapsed Time: 0:00:11 Time:  0:00:11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.10/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/dicts.zip\n",
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dicts into RAM: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "M2QZiFT5d-Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the server**"
      ],
      "metadata": {
        "id": "lgI7VuuleGQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "ngrok.set_auth_token(\"2dOPQRfVjARgr6oi5CQ7gcvefjr_6pcNtTYXhagk29BmjiLQ\")\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ntI6f2eDGY",
        "outputId": "73060baa-5295-4dc6-a9aa-4482fe649dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1266]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://b969-104-198-101-95.ngrok-free.app\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "{'as': 'ফেভিকন.আইচিচি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /favicon.ico HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "{'as': 'ফেভিকন.আইচিচি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /favicon.ico HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi HTTP/1.1\" 200 OK\n",
            "{'as': 'ফেভিকন.আইচিচি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /favicon.ico HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"OPTIONS /tumi HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"OPTIONS /%5Bobject%20Object%5D HTTP/1.1\" 200 OK\n",
            "{'as': '[অৱজেক্ট অৱজেক্ট]'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /%5Bobject%20Object%5D HTTP/1.1\" 200 OK\n",
            "{'as': '[অৱজেক্ট অৱজেক্ট]'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /%5Bobject%20Object%5D HTTP/1.1\" 200 OK\n",
            "{'as': '[অৱজেক্ট অৱজেক্ট]'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /%5Bobject%20Object%5D HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"OPTIONS / HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"OPTIONS /tumi%20ki%20kora HTTP/1.1\" 200 OK\n",
            "{'as': 'তুমি কি কৰা'}\n",
            "INFO:     2409:4065:390:fc4:31fc:7728:9f6e:f440:0 - \"GET /tumi%20ki%20kora HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [1266]\n"
          ]
        }
      ]
    }
  ]
}